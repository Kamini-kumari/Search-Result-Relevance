{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import pipeline,metrics,decomposition\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(rate_a,rate_b,min_rating=None,max_rating=None):\n",
    "    assert(len(rate_a)==len(rate_b))\n",
    "    if min_rating is None:\n",
    "        min_rating=min(rate_a+rate_b)\n",
    "    if max_rating is None:\n",
    "        max_rating=max(rate_a+rate_b)\n",
    "    num_rating=int(max_rating-min_rating+1)\n",
    "    confu_matrix=[[0 for i in range(num_rating)]\n",
    "                 for j in range(num_rating)]\n",
    "    for a,b in zip(rate_a,rate_b):\n",
    "        confu_matrix[a-min_rating][b-min_rating]+=1\n",
    "    return confu_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram(rating,min_rating=None,max_rating=None):\n",
    "    if min_rating is None:\n",
    "        min_rating=min(rating)\n",
    "    if max_rating is None:\n",
    "        max_rating=max(rating)\n",
    "    num_rating=int(max_rating-min_rating+1)\n",
    "    hist=[0 for i in range(num_rating)]\n",
    "    for i in rating:\n",
    "        hist[i-min_rating]+=1\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_weighted_kappa(y,y_pred):\n",
    "    rate_a=y\n",
    "    rate_b=y_pred\n",
    "    rate_a=np.array(rate_a,dtype=int)\n",
    "    rate_b=np.array(rate_b,dtype=int)\n",
    "    min_rating=None\n",
    "    max_rating=None\n",
    "    assert(len(rate_a)==len(rate_b))\n",
    "    if min_rating is None:\n",
    "        min_rating=min(min(rate_a),min(rate_b))\n",
    "    if max_rating is None:\n",
    "        max_rating=max(max(rate_a),max(rate_b))\n",
    "    conf_max=confusion_matrix(rate_a,rate_b,min_rating,max_rating)\n",
    "    num_rating=len(conf_max)\n",
    "    num_scores_item=float(len(rate_a))\n",
    "    hist_a=histogram(rate_a,min_rating,max_rating)\n",
    "    hist_b=histogram(rate_b,min_rating,max_rating)\n",
    "    \n",
    "    numerator=0.0\n",
    "    denominator=0.0\n",
    "    for i in range(num_rating):\n",
    "        for j in range(num_rating):\n",
    "            d=pow(i-j,2.0)/pow(num_rating-1,2.0)\n",
    "            expected=(hist_a[i]*hist_b[j]/num_scores_item)\n",
    "            numerator+=d*conf_max[i][j]/num_scores_item\n",
    "            denominator+=d*expected/num_scores_item\n",
    "    return (1.0-numerator/denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 15657)\t0.261742125188547\n",
      "  (0, 15656)\t0.261742125188547\n",
      "  (0, 15655)\t0.1956813789955167\n",
      "  (0, 15652)\t0.1900282943976819\n",
      "  (0, 13949)\t0.2377917675212798\n",
      "  (0, 13946)\t0.14414965478495423\n",
      "  (0, 12714)\t0.1557160855343555\n",
      "  (0, 8359)\t0.2685203837650798\n",
      "  (0, 8355)\t0.1811466520220755\n",
      "  (0, 5546)\t0.18429960671355355\n",
      "  (0, 5476)\t0.261742125188547\n",
      "  (0, 5475)\t0.261742125188547\n",
      "  (0, 5472)\t0.194998738484414\n",
      "  (0, 3083)\t0.261742125188547\n",
      "  (0, 3082)\t0.261742125188547\n",
      "  (0, 3081)\t0.1956813789955167\n",
      "  (0, 3079)\t0.1956813789955167\n",
      "  (0, 3078)\t0.19433110228300043\n",
      "  (0, 2531)\t0.09900061546307047\n",
      "  (0, 1490)\t0.261742125188547\n",
      "  (0, 1489)\t0.2083450387130452\n",
      "  (1, 18641)\t0.21354786834034664\n",
      "  (1, 17565)\t0.19012113556081284\n",
      "  (1, 15165)\t0.11336238974799137\n",
      "  (1, 12035)\t0.2508803544565089\n",
      "  :\t:\n",
      "  (10156, 18162)\t0.3363994745465213\n",
      "  (10156, 16052)\t0.30536722776026076\n",
      "  (10156, 12860)\t0.39873593048708295\n",
      "  (10156, 6952)\t0.3525856061591716\n",
      "  (10156, 6950)\t0.32808536255146276\n",
      "  (10156, 3180)\t0.580329749738435\n",
      "  (10156, 1358)\t0.2566255526069216\n",
      "  (10157, 17443)\t0.1931031181538848\n",
      "  (10157, 13796)\t0.19047690499593503\n",
      "  (10157, 13794)\t0.3197540057239661\n",
      "  (10157, 13792)\t0.31349365111160205\n",
      "  (10157, 13000)\t0.19220048902738734\n",
      "  (10157, 12999)\t0.188851866745701\n",
      "  (10157, 12998)\t0.188851866745701\n",
      "  (10157, 12997)\t0.188851866745701\n",
      "  (10157, 12987)\t0.31349365111160205\n",
      "  (10157, 12780)\t0.14201018468668905\n",
      "  (10157, 11311)\t0.19047690499593503\n",
      "  (10157, 11303)\t0.28253504030394133\n",
      "  (10157, 10918)\t0.14009941107236024\n",
      "  (10157, 8366)\t0.19047690499593503\n",
      "  (10157, 8364)\t0.3197540057239661\n",
      "  (10157, 8362)\t0.31349365111160205\n",
      "  (10157, 8355)\t0.287061302582715\n",
      "  (10157, 2531)\t0.09265898150683105\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:   41.0s remaining:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:   41.3s remaining:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   42.1s remaining:   42.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   8 | elapsed:  2.0min remaining:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:  2.1min remaining:   41.2s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  2.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scores : 0.556\n",
      "Best parameter :\n",
      "\tsvd__n_components: 400\n",
      "\tsvm__C: 12\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    train=pd.read_csv('train.csv')\n",
    "    test=pd.read_csv('test.csv')\n",
    "    #print(train)\n",
    "    idx=test.id.values.astype(int)\n",
    "    train=train.drop(labels='id',axis=1)\n",
    "    test=test.drop(labels='id',axis=1)\n",
    "    #print(train)\n",
    "    y=train.median_relevance.values\n",
    "    train=train.drop(['median_relevance','relevance_variance'],axis=1)\n",
    "    #print(train)\n",
    "    \n",
    "    traindata=list(train.apply(lambda x:'%s %s' % (x['query'],x['product_title']),axis=1))\n",
    "    testdata=list(test.apply(lambda x:'%s %s' % (x['query'],x['product_title']),axis=1))\n",
    "    #print(traindata)\n",
    "    \n",
    "    tfv=TfidfVectorizer(strip_accents='unicode',analyzer='word',stop_words='english',\n",
    "                        token_pattern=r'\\w{1,}',ngram_range=(1,5),min_df=3,max_features=None,use_idf=1,\n",
    "                       smooth_idf=1,sublinear_tf=1)\n",
    "    tfv.fit(traindata)\n",
    "    x=tfv.transform(traindata)\n",
    "    x_test=tfv.transform(testdata)\n",
    "    #print(x)\n",
    "    svd=TruncatedSVD()\n",
    "    scl=StandardScaler()\n",
    "    svm_model=SVC()\n",
    "    \n",
    "    clf=pipeline.Pipeline([('svd',svd),\n",
    "                          ('scl',scl),\n",
    "                          ('svm',svm_model)]) \n",
    "    \n",
    "    param_grid={'svd__n_components':[200,400],\n",
    "               'svm__C':[10,12]}\n",
    "    \n",
    "    kappa_scorer=metrics.make_scorer(quadratic_weighted_kappa,greater_is_better=True)\n",
    "    \n",
    "    model=GridSearchCV(estimator=clf,param_grid=param_grid,scoring=kappa_scorer,\n",
    "                       n_jobs=-1,iid=True,cv=2,refit=True,verbose=10)\n",
    "    model.fit(x,y)\n",
    "    print('Best scores : %0.3f' % model.best_score_)\n",
    "    print('Best parameter :')\n",
    "    best_param=model.best_estimator_.get_params()\n",
    "    for param_name in sorted(param_grid.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_param[param_name]))\n",
    "    \n",
    "    best_model=model.best_estimator_\n",
    "    best_model.fit(x,y)\n",
    "    pred=best_model.predict(x_test)\n",
    "    solution = pd.DataFrame({\"id\": idx, \"prediction\": pred})\n",
    "    solution.to_csv(\"solution.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
